{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alice-generation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOm5+d8V2CYm/AiAkQL0LY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexbrill/tf-train/blob/main/alice_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYExU9KXFwSy"
      },
      "source": [
        "import sys\n",
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3i6yhs1GC0s",
        "outputId": "a0183a59-a129-415a-cba8-8984d2177a6f"
      },
      "source": [
        "!wget  https://www.gutenberg.org/files/11/11-0.txt -O wonderland.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-27 14:47:51--  https://www.gutenberg.org/files/11/11-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 174313 (170K) [text/plain]\n",
            "Saving to: ‘wonderland.txt’\n",
            "\n",
            "wonderland.txt      100%[===================>] 170.23K   841KB/s    in 0.2s    \n",
            "\n",
            "2021-05-27 14:47:52 (841 KB/s) - ‘wonderland.txt’ saved [174313/174313]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiVpOpXqF1Tu"
      },
      "source": [
        "filename = \"wonderland.txt\"\n",
        "\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsN5SOZSIOEf"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe3B82Y0ISWL",
        "outputId": "d85fd3eb-404e-4730-f53e-159939948f6c"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  164047\n",
            "Total Vocab:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFcSBEIJIZTC",
        "outputId": "18750558-e62c-48f4-b319-1567433bf30a"
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "        seq_in = raw_text[i:i + seq_length]\n",
        "        seq_out = raw_text[i + seq_length]\n",
        "        dataX.append([char_to_int[char] for char in seq_in])\n",
        "        dataY.append(char_to_int[seq_out])\n",
        "\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YeolKlJ5Ifd9"
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F471yuIIhq5"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbt5CmIMIl8V"
      },
      "source": [
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iggITD8IpDi",
        "outputId": "1a0bb08b-883f-4a07-be1a-b97817e9cf78"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1281/1281 [==============================] - 39s 15ms/step - loss: 3.1151\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.02561, saving model to weights-improvement-01-3.0256.hdf5\n",
            "Epoch 2/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.8715\n",
            "\n",
            "Epoch 00002: loss improved from 3.02561 to 2.84716, saving model to weights-improvement-02-2.8472.hdf5\n",
            "Epoch 3/20\n",
            "1281/1281 [==============================] - 19s 14ms/step - loss: 2.7858\n",
            "\n",
            "Epoch 00003: loss improved from 2.84716 to 2.76522, saving model to weights-improvement-03-2.7652.hdf5\n",
            "Epoch 4/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.7101\n",
            "\n",
            "Epoch 00004: loss improved from 2.76522 to 2.69747, saving model to weights-improvement-04-2.6975.hdf5\n",
            "Epoch 5/20\n",
            "1281/1281 [==============================] - 19s 14ms/step - loss: 2.6513\n",
            "\n",
            "Epoch 00005: loss improved from 2.69747 to 2.63658, saving model to weights-improvement-05-2.6366.hdf5\n",
            "Epoch 6/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.5910\n",
            "\n",
            "Epoch 00006: loss improved from 2.63658 to 2.57903, saving model to weights-improvement-06-2.5790.hdf5\n",
            "Epoch 7/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.5356\n",
            "\n",
            "Epoch 00007: loss improved from 2.57903 to 2.52419, saving model to weights-improvement-07-2.5242.hdf5\n",
            "Epoch 8/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.4799\n",
            "\n",
            "Epoch 00008: loss improved from 2.52419 to 2.47626, saving model to weights-improvement-08-2.4763.hdf5\n",
            "Epoch 9/20\n",
            "1281/1281 [==============================] - 19s 14ms/step - loss: 2.4387\n",
            "\n",
            "Epoch 00009: loss improved from 2.47626 to 2.43437, saving model to weights-improvement-09-2.4344.hdf5\n",
            "Epoch 10/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.3966\n",
            "\n",
            "Epoch 00010: loss improved from 2.43437 to 2.39080, saving model to weights-improvement-10-2.3908.hdf5\n",
            "Epoch 11/20\n",
            "1281/1281 [==============================] - 19s 15ms/step - loss: 2.3503\n",
            "\n",
            "Epoch 00011: loss improved from 2.39080 to 2.35469, saving model to weights-improvement-11-2.3547.hdf5\n",
            "Epoch 12/20\n",
            "1281/1281 [==============================] - 19s 14ms/step - loss: 2.3202\n",
            "\n",
            "Epoch 00012: loss improved from 2.35469 to 2.31905, saving model to weights-improvement-12-2.3191.hdf5\n",
            "Epoch 13/20\n",
            "1281/1281 [==============================] - 19s 14ms/step - loss: 2.2833\n",
            "\n",
            "Epoch 00013: loss improved from 2.31905 to 2.28430, saving model to weights-improvement-13-2.2843.hdf5\n",
            "Epoch 14/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.2464\n",
            "\n",
            "Epoch 00014: loss improved from 2.28430 to 2.24908, saving model to weights-improvement-14-2.2491.hdf5\n",
            "Epoch 15/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.2161\n",
            "\n",
            "Epoch 00015: loss improved from 2.24908 to 2.22027, saving model to weights-improvement-15-2.2203.hdf5\n",
            "Epoch 16/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.1757\n",
            "\n",
            "Epoch 00016: loss improved from 2.22027 to 2.19035, saving model to weights-improvement-16-2.1903.hdf5\n",
            "Epoch 17/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.1563\n",
            "\n",
            "Epoch 00017: loss improved from 2.19035 to 2.16255, saving model to weights-improvement-17-2.1625.hdf5\n",
            "Epoch 18/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.1334\n",
            "\n",
            "Epoch 00018: loss improved from 2.16255 to 2.13623, saving model to weights-improvement-18-2.1362.hdf5\n",
            "Epoch 19/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.1089\n",
            "\n",
            "Epoch 00019: loss improved from 2.13623 to 2.11177, saving model to weights-improvement-19-2.1118.hdf5\n",
            "Epoch 20/20\n",
            "1281/1281 [==============================] - 18s 14ms/step - loss: 2.0834\n",
            "\n",
            "Epoch 00020: loss improved from 2.11177 to 2.09131, saving model to weights-improvement-20-2.0913.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd5e81dba50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mI0HggYIw1O"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVHkWGyiIwGF"
      },
      "source": [
        "# load the network weights\n",
        "filename = \"/content/weights-improvement-20-2.0913.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EqshVaoI31Y"
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWArrH9EI5aB",
        "outputId": "85f8ccdb-b354-4b6f-f338-84b91690cea5"
      },
      "source": [
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "\n",
        "# generate characters\n",
        "\n",
        "for i in range(1000):\n",
        "        x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "        x = x / float(n_vocab)\n",
        "        prediction = model.predict(x, verbose=0)\n",
        "        index = numpy.argmax(prediction)\n",
        "        result = int_to_char[index]\n",
        "        seq_in = [int_to_char[value] for value in pattern]\n",
        "        sys.stdout.write(result)\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "print(\"\\nDone.\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" ut all he _said_\n",
            "was, “why is a raven like a writing-desk?”\n",
            "\n",
            "“come, we shall have some fun now!” tho \"\n",
            " daded aliee. \n",
            "“ho  io you said to toe sooele,” shi gatter sepdiked.\n",
            "“oh you dno’t then io wou cene to toe toens!”h\n",
            "toiek to the whuh the mortle oate to the wound beli to the thetg was oo tee toiee and aooeer of the gorse tft ano hor herd the toeee tf the the gar in the toiee and aoo anr anr anr oo the toie, \n",
            "“what did t aade the corsouse then ”ou meke,” said the cat.ra liteing the woide afdin then at she was sorting to the thetg was oooeing an inr tiie, “ho wo leke the dormouser ”ou dad toe cane than i sae so toe then io the mortle  a dat oaid to toink to tee the woide and toeer the was afdin to the thitg was aoi aooiersnn the saeted and the pooe afd no the toiee and the soier of the toiee. and the woile the woile to the toeee of the toiee afdin, and the woide the woile to the toeee of the coort, “and then io whs do aoue of the moot of the moos if the mootte tai it then to toee and the woine  “hht the tee it then toe toieg to the soiee of the soaee of the soaee of the soiee  ald then \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}